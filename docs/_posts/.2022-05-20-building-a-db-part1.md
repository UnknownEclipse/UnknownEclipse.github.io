---
layout: post
title: "Building a Database, Part 1"
date: 2022-05-20 10:21:48 -0700
categories: jekyll update
---

Why? Good question!

...

_Anyway_, let's get started! I'll be using Rust on a MacBook, but I'll make sure to point
out any platform specific quirks to handle as necessary.

Now, to figure out how databases actually work. The general principle behind all database
engines is that they are designed to store and organize data extremely reliably, and
perform queries that operate on that data. Reliability is extremely important, so let's
start with that.

Database writes must be atomic, meaning that even if an error occurs while we are making
a change, none of the changes are visible and the database can be easily restored. This
is quite a challenge, [especially when filesystems are rude enough to have bugs](http://danluu.com/file-consistency/).

The reliability aspect is handled by the storage layer, which turns abstract requests
(write this data here, read this data there) into efficient and reliable filesystem
operations. Let's start by defining our storage layer's interface, then I'll go
more into depth on the choices made.

```rust
pub struct Store {
    // ...
}

pub struct Reader<'store> {
    // ...
}


pub struct Writer<'store> {
    // ...
}

pub struct PageId(u32);

pub struct PageRef<'a>(/* ... */);

impl Store {
    pub fn reader(&self) -> Reader<'_> {
        todo!()
    }

    pub fn writer(&self) -> Writer<'_> {
        todo!()
    }
}

impl<'store> Reader<'store> {
    pub fn get(&self, page: PageId) -> Result<Option<PageRef<'_>>> {
        todo!()
    }
}

impl<'store> Writer<'store> {
    pub fn get(&self, page: PageId) -> Result<Option<PageRef<'_>>> {
        todo!()
    }

    pub fn write(&mut self, start: usize, data: &[u8]) -> Result<()> {
        todo!()
    }

    pub fn commit(self) -> Result<()> {
        todo!()
    }

    pub fn rollback(self) -> Result<()> {
        todo!()
    }
}
```

The core of our storage layer is the `Store` struct. On its own, it can't do much.
We don't allow reads or writes to occur directly on the `Store`. Instead, we have
methods that return `Reader`s and `Writer`s which allow those operations. Both of these
methods work on _snapshots_ of the database, which is important. Imagine if, at the same
time as you tried to read some data, that same data was being rearranged by a writer.
Chaos ensues! (This is also what Rust's borrow checker stops).

`Reader`s only have one method: `get()`, which returns a page with the given id if it
exists. Pretty simple. `Writer`s on the other hand, have a whole bunch of other methods.
The most basic here is `write()`, which writes some data into a page at the requested
offset. The next two are `commit()` and `rollback()`. These two are related. The idea
is that, once the database is done with a write operation, those writes can be atomically
'committed', or made visible to readers and essentially become part of the database.
Until that data is committed, readers will continue to view the database before any
of those writes occurred. A rollback does the opposite, essentially saying, "hey, yeah
I know I did all that writing, but what if you like... forgot." In other words,
the writes made during that write transaction will be forgotten.

`Writer`s and `Reader`s

Now that we have our API planned out, let's actually look into how this madness actually
works. The general setup we will be using is known as a _Write Ahead Log_, which is a
file that we 'log' new records to. When we write a page update, that delta gets
appended to the log. When a commit or rollback occurs, we just append the corresponding
log record and keep going. Readers maintain a special value that indicates the end of
the log at the time that reader was created. Now, reads can occur on the log
prior to that point in time, giving us an efficient snapshot mechanism.

We will also need to implement a 'checkpoint' mechanism, where the records in the log
are written back to the main database file and the log is truncated. This is the key
point where data corruption can occur, so if any of the writes to the database fails,
the correct data is still in the log ready for use in recovery.

One thing to bear in mind is that if we have multiple writers then records may become
interleaved, resulting in dragons and demons. To work around this, we can just limit
the number of concurrent writers to 1. (Side note, because of the way we design
our `Store`, if we ever find a better way of doing this, none of the high level
code needs to change!). So we make sure to put a writer mutex in the store, and make
sure both the log and the database files are locked exclusively and... Where is that
screaming coming from?

### The POSIX File Lock Nightmare

Ok so... nothing is simple, especially with this kind of low level, platform specific
code. The problem we hit here is that, at least on POSIX systems (Linux, MacOS, etc.),
file locks are broken by design.

#### WHYYYY?

So... yeah. The problem with file locks stems from one very important detail: a lock
is _per-process_. Yes, that is exactly as bad as it sounds. Attempting to open the same
database from the same process will cause one of connections to overwrite the other's
lock silently, causing data corruption in multi-threaded workloads. Also, if _any_ file
descriptor related to that file is closed, _every lock held by that process is also
dropped_. Fun.

#### The Workaround

So to workaround this issue, we need to do several things:

-   Ensure that the same process can not overwrite locks on contested files.
-   Ensure that no files are closed until all locks associated with them are dropped.

To fix this, we're going to use a global hash table.

```rust
static LOCK_TABLE: Lazy<Mutex<HashMap<FileId, Weak<Mutex<LockData>>>>> = Lazy::new(Default::default);
```

That is... quite the nested type, but it's quite manageable once we start stripping
layers of nesting away. First, the `Lazy<Mutex<_>>` is just to make it static-safe,
so we can remove that, giving us `HashMap<FileId, Weak<Mutex<LockData>>>`. This is way
better. This table is basically just a mapping of file ids to shared, per-file
lock objects.

Wait... file ids?

We need to be able to uniquely identify a file on the file system. Path's won't
work due to hardlinks and other filesystem shenanigans (on top of being racy if a
rename occurs). Looking into the documentation for `stat(2)` we find these two fields

```c
struct stat {
    dev_t st_dev;
    ino_t st_ino;
    // ...
};
```

The `st_dev` is the device identifer, while the `st_ino` is the file's inode number on
that device. The combination of these two is guaranteed to be unique. Great! So now we
can just define our structure as follows:

```rust
#[derive(Debug, Clone, Copy, PartialEq, Eq, Hash)]
pub struct FileId {
    ino: u64,
    dev: u64
}
```

And luckily, Rust's `Metadata` type has a Unix extension trait that exposes this
information, so we can easily get the id of a given file without needing to use `libc`!

```rust
pub fn get_file_id(file: &File) -> io::Result<FileId> {
    let meta = file.metadata()?;
    Ok(FileId {
        ino: meta.ino(),
        dev: meta.dev()
    })
}
```

Now that that's out of the way, we need to define a new file.

```rust
pub struct UnixFile {
    inner: File,
    lock_data: Arc<Mutex<LockData>>
}
```

When we create or open a new file, we look up that lock data structure in the global
hash table, creating a fresh one if the weak pointer in the hash table does not actually
point anywhere (the reason we use a `Weak` will become clear soon). Then we just hold
onto that shared structure in the file.

Now to define what we hold in this shared structure. First, we need to maintain a list
of files that have been dropped while a lock is held. Remember, this can result in an
unexpected unlock so we need to hold onto them.

```rust
struct LockData {
    retired: Vec<File>
    // ...
}
```

Now the tricky part: The locked ranges of the file.

```rust
struct LockData {
    ranges: Vec<(LockRange, LockState)>
    // ..
}

enum Lockstate {
    Unlocked,
    Exclusive(RawFd),
    Shared(usize),
}

struct LockRange {
    start: u64,
    len: Option<NonZeroU64>
}
```
